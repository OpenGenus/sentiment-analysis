{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4dcea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fdb62d",
   "metadata": {},
   "source": [
    "# Naive implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2411bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral'], dtype='<U7')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def lowercase(text):\n",
    "    lowercase_chars = [char.lower() if char.isalpha()  else \" \" for char in text]\n",
    "    return \"\".join(lowercase_chars)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = lowercase(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS]\n",
    "    text = \"  \".join(tokens)\n",
    "    return text\n",
    "\n",
    "#Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def extract_features(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    features = vectorizer.fit_transform([text])\n",
    "    return features\n",
    "def train_classification_model(clf, text, assigned_label):\n",
    "    text1= preprocess(text)\n",
    "    features = extract_features(text1)\n",
    "    features\n",
    "    clf.fit(features, [assigned_label])\n",
    "    return clf\n",
    "\n",
    "def test_model(clf, test):\n",
    "    return clf.predict(extract_features(preprocess(test)))\n",
    "\n",
    "clf=MultinomialNB()\n",
    "train_classification_model(clf, \"I love this movie! The acting was superb and the storyline was captivating.\", 'Positive')\n",
    "train_classification_model(clf, \"I hated the movie, the acting was bad and the storyline was boring.\", 'Negative')\n",
    "train_classification_model(clf, \"The movie was okay, average in terms of acting and story.\", 'Neutral')\n",
    "\n",
    "test_model(clf, \"The movie was average  in terms of everything. Could be better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881696b7",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05339b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C://Users//Ambarish Deb//Downloads//IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb00c2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4da90ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one  review  ha  mention  watch  oz  episod  h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder  littl  product  film  techniqu  veri  ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought  thi  wa  wonder  way  spend  time  ho...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic  famili  littl  boy  jake  think  zombi ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter  mattei  love  time  money  visual  stu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one  review  ha  mention  watch  oz  episod  h...  positive\n",
       "1  wonder  littl  product  film  techniqu  veri  ...  positive\n",
       "2  thought  thi  wa  wonder  way  spend  time  ho...  positive\n",
       "3  basic  famili  littl  boy  jake  think  zombi ...  negative\n",
       "4  petter  mattei  love  time  money  visual  stu...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem import *\n",
    "import re\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def lowercase(text):\n",
    "    lowercase_chars = [char.lower() if char.isalpha()  else \" \" for char in text]\n",
    "    return \"\".join(lowercase_chars)\n",
    "\n",
    "def preprocess(text):\n",
    "    cleaner = re.compile('<.*?>')\n",
    "    text = re.sub(cleaner, '', text)\n",
    "    text = lowercase(text)\n",
    "    text= ' '.join([PorterStemmer().stem(word) for word in text.split()])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS]\n",
    "    text = \"  \".join(tokens)\n",
    "    return text\n",
    "\n",
    "df['review']=df['review'].apply(lambda x: preprocess(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc539d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000,)\n",
      "(10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_reviews=df.review[:40000]\n",
    "train_sentiments=df.sentiment[:40000]\n",
    "#test dataset\n",
    "test_reviews=df.review[40000:]\n",
    "test_sentiments=df.sentiment[40000:]\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "print(test_reviews.shape,test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15d130",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda35829",
   "metadata": {},
   "source": [
    "#### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb63997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (40000, 5836829)\n",
      "BOW_cv_test: (10000, 5836829)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train_reviews=cv.fit_transform(train_reviews)\n",
    "#transformed test reviews\n",
    "cv_test_reviews=cv.transform(test_reviews)\n",
    "\n",
    "print('BOW_cv_train:',cv_train_reviews.shape)\n",
    "print('BOW_cv_test:',cv_test_reviews.shape)\n",
    "#vocab=cv.get_feature_names()-toget feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d1930",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bbd0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (40000, 5836829)\n",
      "Tfidf_test: (10000, 5836829)\n"
     ]
    }
   ],
   "source": [
    "#Tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(train_reviews)\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(test_reviews)\n",
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e45f6",
   "metadata": {},
   "source": [
    "### Model Training & Performance Metrics\n",
    "We'll train two separate models, one for the bag of words approach and the other ffor the TF-IDF approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c2987dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.57      0.97      0.71      4993\n",
      "    negative       0.89      0.26      0.40      5007\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.73      0.61      0.56     10000\n",
      "weighted avg       0.73      0.61      0.56     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "lr=LogisticRegression(random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
    "test_sentiments_pred = lr_bow.predict(cv_test_reviews)\n",
    "\n",
    "target_names = ['positive','negative'] # target values\n",
    "\n",
    "# Print classification report after a train/test split:\n",
    "print(classification_report(test_sentiments, test_sentiments_pred , target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3cfc8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4840,  153],\n",
       "       [3718, 1289]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_sentiments, test_sentiments_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c612b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3827 1166]\n",
      " [1325 3682]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.74      0.77      0.75      4993\n",
      "    negative       0.76      0.74      0.75      5007\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.75     10000\n",
      "weighted avg       0.75      0.75      0.75     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr=LogisticRegression(random_state=100)\n",
    "#Fitting the model for TFIDF\n",
    "lr_tv=lr.fit(tv_train_reviews,train_sentiments)\n",
    "test_sentiments_pred = lr_tv.predict(tv_test_reviews)\n",
    "\n",
    "target_names = ['positive','negative'] # target values\n",
    "\n",
    "# Print classification report after a train/test split:\n",
    "print(confusion_matrix(test_sentiments, test_sentiments_pred))\n",
    "print(classification_report(test_sentiments, test_sentiments_pred , target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0d048",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using sentiment lexicon AFINN-165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc46b42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandons</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abducted</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abduction</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "word            \n",
       "abandon       -2\n",
       "abandoned     -2\n",
       "abandons      -2\n",
       "abducted      -2\n",
       "abduction     -2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn = pd.read_csv(\"C://Users//Ambarish Deb//Desktop//AFINN-165.txt\", sep='\\t', header=None, names=['word', 'score'], index_col='word')\n",
    "afinn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ceb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(text):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in afinn.index:\n",
    "            score += afinn.loc[word]['score']\n",
    "    return score\n",
    "\n",
    "def sentiment(text):\n",
    "    if sentiment_score(text)>0:\n",
    "        return \"Positive Sentiment; Score is : \"+str(sentiment_score(text))\n",
    "    elif sentiment_score(text)==0:\n",
    "        return \"Neutral Sentiment; Score is : \"+str(sentiment_score(text))\n",
    "    else:\n",
    "        return \"Negative Sentiment; Score is : \"+str(sentiment_score(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d68d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive Sentiment; Score is : 7'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"This a fantastic movie of three prisoners who become famous. One of the actors is george clooney and I\\'m not a fan but this roll is not bad. Another good thing about the movie is the soundtrack (The man of constant sorrow). I recommand this movie to everybody. Greetings Bart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d9cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
